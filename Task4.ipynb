{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jg-5loyK9UGU"
      },
      "outputs": [],
      "source": [
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "connect = sqlite3.connect('database.sqlite')\n",
        "cur = connect.cursor()"
      ],
      "metadata": {
        "id": "Tb7f23R9_uEd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdfHpFkF_wrz",
        "outputId": "9cdab684-fa92-4fb6-a2cb-37536ad9a171"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.1"
      ],
      "metadata": {
        "id": "klUTRIDUAWO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mueW_ExBAUe1",
        "outputId": "82f2b217-691a-4117-a844-b95ac4722c1a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3, pandas as pd, re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "con = sqlite3.connect(\"database.sqlite\")\n",
        "\n",
        "posts = pd.read_sql_query(\"SELECT content FROM posts\", con)\n",
        "comments = pd.read_sql_query(\"SELECT content FROM comments\", con)\n",
        "texts = pd.concat([posts[\"content\"], comments[\"content\"]], ignore_index=True).fillna(\"\").astype(str)\n",
        "\n",
        "vec = CountVectorizer(lowercase=True, stop_words='english', max_df=0.40, min_df=5)\n",
        "X = vec.fit_transform(texts)\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10, learning_method='batch', random_state=42, max_iter=20)\n",
        "lda.fit(X)\n",
        "\n",
        "vocab = vec.get_feature_names_out()\n",
        "for k, comp in enumerate(lda.components_):\n",
        "    top = comp.argsort()[::-1][:10]\n",
        "    print(f\"Topic {k}: \" + \", \".join(vocab[i] for i in top))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAebZyhB_ysT",
        "outputId": "dd414063-be6c-4240-a191-2c6479639523"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: like, just, feels, wow, feel, people, hard, seriously, really, trying\n",
            "Topic 1: just, people, let, real, like, fashion, need, seriously, big, hype\n",
            "Topic 2: love, amazing, remember, new, similar, curious, year, perspective, change, like\n",
            "Topic 3: think, just, let, maybe, real, people, isn, need, bit, important\n",
            "Topic 4: like, just, time, haha, new, perfect, sounds, good, day, best\n",
            "Topic 5: post, really, sharing, thanks, amazing, reading, makes, hit, truly, little\n",
            "Topic 6: like, remember, nature, just, tried, ended, time, sounds, hey, day\n",
            "Topic 7: music, new, exploring, vegan, just, hidden, mind, time, food, like\n",
            "Topic 8: great, community, project, diy, remember, garden, pushing, energy, ve, just\n",
            "Topic 9: just, like, maybe, book, time, try, feeling, oh, sounds, seriously\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.2\n"
      ],
      "metadata": {
        "id": "YwH0KATwGSca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# --- setup ---\n",
        "nltk.download(\"vader_lexicon\", quiet=True)\n",
        "dbPath = \"database.sqlite\"\n",
        "\n",
        "def cleanText(t: str) -> str:\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"http\\S+|@\\S+|#[\\w-]+\", \" \", t)\n",
        "    t = re.sub(r\"[^a-z\\s']\", \" \", t)\n",
        "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "def toBucket(c: float) -> str:\n",
        "    if c >= 0.05: return \"pos\"\n",
        "    if c <= -0.05: return \"neg\"\n",
        "    return \"neu\"\n",
        "\n",
        "with sqlite3.connect(dbPath) as conn:\n",
        "    posts = pd.read_sql(\"SELECT id, content FROM posts\", conn)\n",
        "    comments = pd.read_sql(\"SELECT id, content FROM comments\", conn)\n",
        "\n",
        "df = pd.concat(\n",
        "    [\n",
        "        posts.rename(columns={\"content\": \"text\"})[[\"text\"]].assign(kind=\"post\"),\n",
        "        comments.rename(columns={\"content\": \"text\"})[[\"text\"]].assign(kind=\"comment\"),\n",
        "    ],\n",
        "    ignore_index=True,\n",
        ")\n",
        "\n",
        "df = df.dropna(subset=[\"text\"]).copy()\n",
        "df[\"text\"] = df[\"text\"].astype(str).apply(cleanText)\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "df[\"compound\"] = df[\"text\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
        "df[\"bucket\"] = df[\"compound\"].apply(toBucket)\n",
        "\n",
        "#  tone\n",
        "overallMean = df[\"compound\"].mean()\n",
        "mix = df[\"bucket\"].value_counts(normalize=True).mul(100)\n",
        "\n",
        "print(\"\\n>>>>>>>>>Overall Platform Tone<<<<<<<<<<<<< \")\n",
        "print(f\"Docs analyzed: {len(df)}\")\n",
        "print(f\"Average sentiment (compound): {overallMean:.3f}\")\n",
        "print(\n",
        "    f\"Positive: {mix.get('pos', 0):.1f}%  \"\n",
        "    f\"Neutral: {mix.get('neu', 0):.1f}%  \"\n",
        "    f\"Negative: {mix.get('neg', 0):.1f}%\"\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNLR6bnS_1bl",
        "outputId": "f251da80-c784-4349-ae2d-753fac35a6d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>>>>>>>>Overall Platform Tone<<<<<<<<<<<<< \n",
            "Docs analyzed: 7107\n",
            "Average sentiment (compound): 0.407\n",
            "Positive: 74.9%  Neutral: 7.7%  Negative: 17.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.3\n",
        "\n",
        "(on the word Homework coursebook)"
      ],
      "metadata": {
        "id": "Co1gFjz-DBLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.4\n",
        "\n",
        "(on the word Homework coursebook)"
      ],
      "metadata": {
        "id": "pWsflrioI7Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbF8PaoFDS3D"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}